import numpy as np
from gym import utils
from gym.envs.mujoco import mujoco_env

import mujoco_py
from mujoco_py.mjlib import mjlib
from PIL import Image

class PusherEnv(mujoco_env.MujocoEnv, utils.EzPickle):
    def __init__(self, xml_file=None, distractors=False):
        utils.EzPickle.__init__(self)
        print(xml_file)
        if xml_file is None:
            xml_file = 'pusher.xml'
        self.include_distractors = distractors
        mujoco_env.MujocoEnv.__init__(self, xml_file, 5)

    def get_current_obs(self):
        return self._get_obs()

    def step(self, action):
        return self._step(a=action)

    def _step(self, a):
        # normalize actions
        if self.action_space is not None:
            lb, ub = self.action_space.low, self.action_space.high
            a = lb + (a + 1.) * 0.5 * (ub - lb)
            a = np.clip(a, lb, ub)

        vec_1 = self.get_body_com("object") - self.get_body_com("tips_arm")
        vec_2 = self.get_body_com("object") - self.get_body_com("goal")

        reward_near = - np.linalg.norm(vec_1)
        reward_dist = - np.linalg.norm(vec_2)
        reward_ctrl = - np.square(a).sum()
        reward = reward_dist + 0.1 * reward_ctrl + 0.5 * reward_near

        self.do_simulation(a, self.frame_skip)
        # extra added to copy rllab forward_dynamics.
        self.model.forward()

        ob = self._get_obs()
        done = False
        return ob, reward, done, dict(reward_dist=reward_dist,
                reward_ctrl=reward_ctrl)


    def viewer_setup(self):
        self.viewer.cam.trackbodyid = -1
        self.viewer.cam.distance = 4.0

    def reset_model(self):
        qpos = self.init_qpos

        self.goal_pos = np.asarray([0, 0])
        while True:
            self.obj_pos = np.concatenate([
                    np.random.uniform(low=-0.3, high=0, size=1),
                    np.random.uniform(low=-0.2, high=0.2, size=1)])
            if np.linalg.norm(self.obj_pos - self.goal_pos) > 0.17:
                break

        if self.include_distractors:
            if self.obj_pos[1] < 0:
                y_range = [0.0, 0.2]
            else:
                y_range = [-0.2, 0.0]
            while True:
                self.distractor_pos = np.concatenate([
                        np.random.uniform(low=-0.3, high=0, size=1),
                        np.random.uniform(low=y_range[0], high=y_range[1], size=1)])
                if np.linalg.norm(self.distractor_pos - self.goal_pos) > 0.17 and np.linalg.norm(self.obj_pos - self.distractor_pos) > 0.1:
                    break
            qpos[-6:-4] = self.distractor_pos


        qpos[-4:-2] = self.obj_pos
        qpos[-2:] = self.goal_pos
        qvel = self.init_qvel + np.random.uniform(low=-0.005,
                high=0.005, size=(self.model.nv))

        #qvel[-4:] = 0
        #self.set_state(qpos, qvel)
        #return self._get_obs()

        setattr(self.model.data, 'qpos', qpos)
        setattr(self.model.data, 'qvel', qvel)
        self.model.data.qvel = qvel
        self.model._compute_subtree()
        self.model.forward()
        self.current_com = self.model.data.com_subtree[0]
        self.dcom = np.zeros_like(self.current_com)
        return self._get_obs()

    def get_current_image_obs(self):
        image = self.viewer.get_image()
        pil_image = Image.frombytes('RGB', (image[1], image[2]), image[0])
        pil_image = pil_image.resize((125,125), Image.ANTIALIAS)
        image = np.flipud(np.array(pil_image))
        return image, np.concatenate([
            self.model.data.qpos.flat[:7],
            self.model.data.qvel.flat[:7],
            self.get_body_com('tips_arm'),
            self.get_body_com('goal'),
            ])


    def _get_obs(self):
        if self.include_distractors:
            return np.concatenate([
                self.model.data.qpos.flat[:7],
                self.model.data.qvel.flat[:7],
                self.get_body_com("tips_arm"),
                self.get_body_com("distractor"),
                self.get_body_com("object"),
                self.get_body_com("goal"),
            ])
        else:
            return np.concatenate([
                self.model.data.qpos.flat[:7],
                self.model.data.qvel.flat[:7],
                self.get_body_com("tips_arm"),
                self.get_body_com("object"),
                self.get_body_com("goal"),
            ])
